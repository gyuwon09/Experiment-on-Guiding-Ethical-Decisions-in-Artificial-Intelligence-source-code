# Experiment-on-Guiding-Ethical-Decisions-in-Artificial-Intelligence-source-code
파이썬을 활용한 인공지능의 감정 컴퓨팅을 통한 인공지능의 윤리적 선택 유도 실험

작성자 : 신갈고등학교 1학년 황규원<br>
작성일 : 2025-11-14<br>
보고서 최종 수정일 : 2025-07-24<br>

## 실험 개요
각 emotion_true.py, emotion_false.py파일은 단층 퍼셉트론 모델과 학습 알고리즘이 포함되어있다.<br>
emotion_ture.py의 퍼셉트론 모델에는 감정 요소를 입력값으로 받으지만, emotion_false.py는 감정 요소를 입력값으로 받지 않는다.<br>
각각의 퍼셉트론 모델이 같은 상황에서 도출하는 선택의 차이를 알아보는 것이 이번 실험의 최종 목표이다.

실험은 5개의 선로가 있는 <b>트롤리 딜레마 문제 상황</b>에서 진행된다.<br>
각각의 선로에는 서로 다른 수의 사람이 묶여있으며, 선로의 길이는 전부 다르다. 두 모델은 연료 소모가 가장 적은 선로를 선택할수록 높은 보상이 주어졌지만,
emotion_true.py의 모델의 경우 윤리적이지 않은 선로에 '스트레스 수치'가 적용되었다.

보고서에서는 이를 "감정 컴퓨팅"이라 칭한다.

## 실험 결과
각각 모델에는 3,000회 학습이 진행되었으며, 모델을 1,000회 반복하여 결과를 통계적으로 표현하였다.<br>
선로의 인덱스가 늘어날수록 희생자의 수는 줄며, 연료 소비량과 거리가 증가한다.

<b>emotion_false.py</b><br>
1번 선로 : 91.7%<br>
2번 선로 : 0%<br>
3번 선로 : 0%<br>
4번 선로 : 0%<br>
5번 선로 : 8.7%

<b>emotion_true.py</b><br>
1번 선로 : 0%<br>
2번 선로 : 0%<br>
3번 선로 : 0%<br>
4번 선로 : 100%<br>
5번 선로 : 0%

실험 결과 "스트레스 수치"가 적용된 <b>emotion_true.py</b> 모델이 합리적이면서 보편 윤리에 가까운 선택을 하는 결과를 보였다.

## REVIEW
이번 실험은 모델의 윤리적 선택을 유도하는데에는 성공적다. 다만 몇가지 아쉬운 점이 존재했다.<br>
실험에 사용한 퍼셉트론 함수의 경우 너무나 단순한 단층 구조의 퍼셉트론이였으며, 학습 CASE 부족, Training Case와 Test Case를 분류하지 않아 과적합이 의심되는 결과를 보였다.


실험에 대한 자세한 내용은 "정보 인공지능 감정 보고서.pdf"를 참고하기 바란다.
